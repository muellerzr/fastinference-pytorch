{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp rebuild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rebuild\n",
    "> Functions needed to rebuild vision-based transforms from export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import io, operator, pickle, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from numpy import ndarray\n",
    "from fastcore.utils import _patched, store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastinference_pytorch.transforms.vision import *\n",
    "from fastinference_pytorch.transforms.data import *\n",
    "from fastinference_pytorch.utils import to_device, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickling export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_data(path:Path=Path('.'), fn='data'):\n",
    "    \"Opens `pkl` file containing exported `Transform` information\"\n",
    "    if '.pkl' not in fn: fn += '.pkl'\n",
    "    if not isinstance(path, Path): path = Path(path)\n",
    "    with open(path/fn, 'rb') as handle:\n",
    "        tfmd_dict = pickle.load(handle)\n",
    "    return tfmd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_model(path:Path=Path('.'), fn='model', cpu=True): \n",
    "    if '.pkl' not in fn: fn += '.pkl'\n",
    "    if not isinstance(path, Path): path = Path(path)\n",
    "    return torch.load(path/fn, map_location='cpu' if cpu else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmd_dict = load_data(path)\n",
    "net = load_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `data_funcs`\n",
    "\n",
    "`data_funcs` are designed to be quick references to tell your `Learner` how your data is going to come in. Below is an example for grabbing images, however this should be however you expect your data to be coming in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image(fn, mode='RGB'): return PILBase.create(fn,mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "These generate our transform \"pipelines\" (as we're not using `fastcore`'s `Pipeline`) to pass our data through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_tfm(key, tfms): \n",
    "    \"Makes a transform from `key`. Class or function must be in global memory (imported)\"\n",
    "    args = tfms[key]\n",
    "    return globals()[key](**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_pipeline(tfms, order=True) -> dict:\n",
    "    \"Generate `pipe` of transforms from dict and (potentially) sort them\"\n",
    "    pipe = []\n",
    "    for key in tfms.keys():\n",
    "        tfm = get_tfm(key, tfms)\n",
    "        pipe.append(tfm)\n",
    "    if order: pipe = sorted(pipe, key=operator.attrgetter('order'))\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_pipelines(tfms) -> dict: \n",
    "    \"Make `item` and `batch` transform pipelines\"\n",
    "    pipe, keys = {}, ['after_item', 'after_batch']\n",
    "    for key in keys:\n",
    "        pipe[key] = generate_pipeline(tfms[key], True)\n",
    "    if not any(isinstance(x, ToTensor) for x in pipe['after_item']):\n",
    "        pipe['after_item'].append(ToTensor(False))\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = generate_pipeline(tfmd_dict['after_item'])\n",
    "batch = generate_pipeline(tfmd_dict['after_batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmd_dict['after_batch'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipelines(tfmd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner():\n",
    "    \"\"\"\n",
    "    Similar to a `fastai` learner for inference\n",
    "\n",
    "    Params:\n",
    "      > `path`: The exact path to where your data and model is stored, relative to the `cwd`\n",
    "      > `data_fn`: Filename of your pickled data\n",
    "      > `model_fn`: Filename of your model\n",
    "      > `data_func`: A function in which has the ability to grab your data based on some input.\n",
    "                     The default grabs an image in a location and opens it with Pillow\n",
    "      > `bs`: The batch size you are wanting to use per inference (this can be tweaked later)\n",
    "      > `cpu`: Whether to use the CPU or GPU\n",
    "\n",
    "    Example use:\n",
    "\n",
    "    learn = Learner('models/data', 'models/model', data_func=image_getter, bs=4, cpu=True)\n",
    "    \"\"\"\n",
    "    def __init__(self, path = Path('.'), data_fn='data', model_fn='model', data_func=None, bs=16, cpu=False): \n",
    "        data = load_data(path, data_fn)\n",
    "        self.n_inp = data['n_inp']\n",
    "        self.pipelines = make_pipelines(data)\n",
    "        self.after_item = self.pipelines['after_item']\n",
    "        self.after_batch = self.pipelines['after_batch']\n",
    "        self.tfm_y = generate_pipeline(data['tfms'], order=False)\n",
    "        self.model = load_model(path, model_fn, cpu)\n",
    "        self.device = 'cpu' if cpu else 'cuda'\n",
    "        store_attr(self, 'data_func,bs')\n",
    "        self.decode_func = None\n",
    "        \n",
    "    def _make_data(self, data):\n",
    "        \"Passes `data` through `after_item` and `after_batch`, splitting into batches\"\n",
    "        self.n_batches = len(data) // self.bs + (0 if len(data)%self.bs == 0 else 1)\n",
    "        batch,batches = [],[]\n",
    "        for d in data:\n",
    "            d = self.data_func(d)\n",
    "            for tfm in self.after_item: d = tfm(d)\n",
    "            batch.append(d)\n",
    "            if len(batch) == self.bs or (len(batches) == self.n_batches - 1 and len(batch) == len(data)):\n",
    "                batch = torch.stack(batch, dim=0)\n",
    "                batch = to_device(batch, self.device)\n",
    "                for tfm in self.after_batch: \n",
    "                    batch = tfm(batch)\n",
    "                batches.append(batch)\n",
    "                batch = []\n",
    "        return batches\n",
    "    \n",
    "    def _decode_inputs(self, inps, outs):\n",
    "        \"Decodes images through `after_batch`\"\n",
    "        for tfm in self.after_batch[::-1]:\n",
    "            if hasattr(tfm, 'can_decode'):\n",
    "                inps = to_device(tfm(inps, decode=True))\n",
    "        outs.insert(len(outs), inps)\n",
    "        return outs\n",
    "    \n",
    "    def get_preds(self, data, raw_outs=False, decode_func=None, with_input=False):\n",
    "        \"\"\"\n",
    "        Gather predictions on `data` with possible decoding. \n",
    "        \n",
    "        Params:\n",
    "          > `data`: Incoming data formatted to what `self.data_func`is expecting\n",
    "          > `raw_outs`: Whether to return the raw outputs\n",
    "          > `decode_func`: A function to use for decoding potential outputs.\n",
    "                           While the default is `None`, see `decode_cel` for an example\n",
    "          > `with_input`: Whether to return a decoded input up to what the model was passed\n",
    "        \"\"\"\n",
    "        inps, outs, dec_out, raw = [],[],[],[]\n",
    "        batches = self._make_data(data)\n",
    "        if self.n_inp > 1:\n",
    "            [inps.append([]) for _ in range(n_inp)]\n",
    "        with torch.no_grad():\n",
    "            for batch in batches:\n",
    "                if with_input:\n",
    "                    if self.n_inp > 1:\n",
    "                        for i in range(self.n_inp):\n",
    "                            inps[i].append(batch[i].cpu())\n",
    "                        else:\n",
    "                            inps.append(batch[0].cpu())\n",
    "                self.model.eval()\n",
    "                out = self.model(batch[:self.n_inp])\n",
    "            raw.append(out)\n",
    "            if self.decode_func is not None: dec_out.append(decode_func(out))\n",
    "        raw = torch.cat(raw, dim=0).cpu().numpy()\n",
    "        if self.decode_func is not None: dec_out = torch.cat(dec_out, dim=0)\n",
    "        if self.decode_func is None or raw_outs: outs.insert(0, raw)\n",
    "        else: outs.insert(0, raw)\n",
    "        \n",
    "        if with_input: outs = self._decode_inputs(inps, outs)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(path='../', data_func=get_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [path/'forest.jpg', path/'forest-Copy1.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 15.4 ms, total: 117 ms\n",
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = learn._make_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 20.8 ms, total: 124 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = learn.get_preds(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5.075976  , -1.2860683 ,  0.28139827,  1.3314227 ,  0.24555245,\n",
       "         -1.267573  ,  0.839015  , -6.593617  , -2.1617684 , -1.9049999 ,\n",
       "         -2.9269905 ,  5.585224  ,  3.2263792 , -1.6155014 , -0.6794665 ,\n",
       "          3.3905056 , -2.9616075 , -1.4418863 ,  0.9092367 , -1.1158583 ,\n",
       "          1.2579541 ,  4.975295  , -0.7700971 , -0.5027274 ,  1.9125727 ,\n",
       "         -0.46821177, -3.2195568 ,  1.3048875 ,  2.3925881 , -2.7260544 ,\n",
       "         -6.7417536 ,  4.4691014 ,  3.138262  , -4.310676  , -1.2019831 ,\n",
       "         -0.27300605,  4.1942105 ]], dtype=float32)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 460, 460])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 37])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
