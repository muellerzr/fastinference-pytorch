{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_core.utils\n",
    "\n",
    "> General utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from fastcore.utils import is_listy, is_iter\n",
    "from fastcore.utils import MethodWrapperType, BuiltinFunctionType, BuiltinMethodType, MethodType, FunctionType\n",
    "from fastcore.dispatch import patch, cast\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def noop(x=None, *args,**kwargs):\n",
    "    \"Do nothing\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply(func, x, *args, **kwargs):\n",
    "    \"Apply `func` recursively to `x`, passing on args\"\n",
    "    if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n",
    "    if isinstance(x,dict):  return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n",
    "    res = func(x, *args, **kwargs)\n",
    "    return res if x is None else retain_type(res, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def retain_type(new, old=None, typ=None, copy_meta=False):\n",
    "    \"Cast `new` to type of `old` or `typ` if it's a superclass\"\n",
    "    # e.g. old is TensorImage, new is Tensor - if not subclass then do nothing\n",
    "    if new is None: return\n",
    "    assert old is not None or typ is not None\n",
    "    if typ is None:\n",
    "        if not isinstance(old, type(new)): return new\n",
    "        typ = old if isinstance(old,type) else type(old)\n",
    "    # Do nothing the new type is already an instance of requested type (i.e. same type)\n",
    "    if typ==type(None) or isinstance(new, typ): return new\n",
    "    return retain_meta(old, cast(new, typ), copy_meta=copy_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def retain_meta(x, res, copy_meta=False):\n",
    "    \"Call `res.set_meta(x)`, if it exists\"\n",
    "    if hasattr(res,'set_meta'): res.set_meta(x, copy_meta=copy_meta)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_device(b, device='cpu'):\n",
    "    \"Recursively put `b` on `device`.\"\n",
    "    def _inner(o): return o.to(device, non_blocking=True) if isinstance(o,Tensor) else o.to_device(device) if hasattr(o, \"to_device\") else o\n",
    "    return apply(_inner, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tensor(x, *rest, **kwargs):\n",
    "    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n",
    "    if len(rest): x = (x,)+rest\n",
    "    res = (x if isinstance(x, Tensor)\n",
    "           else torch.tensor(x, **kwargs) if isinstance(x, (tuple,list))\n",
    "           else _array2tensor(x) if isinstance(x, np.ndarray)\n",
    "           else torch.as_tensor(x, **kwargs) if hasattr(x, '__array__') or is_iter(x)\n",
    "           else _array2tensor(np.array(x), **kwargs))\n",
    "    if res.dtype is torch.float64: return res.float()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ArrayBase(ndarray):\n",
    "    @classmethod\n",
    "    def _before_cast(cls, x): return x if isinstance(x,ndarray) else array(x)\n",
    "\n",
    "class ArrayImageBase(ArrayBase):\n",
    "    _show_args = {'cmap':'viridis'}\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        return show_image(self, ctx=ctx, **{**self._show_args, **kwargs})\n",
    "    \n",
    "class ArrayImage(ArrayImageBase): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _array2tensor(x):\n",
    "    if x.dtype==np.uint16: x.astype(np.float32)\n",
    "    return torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_numpy(self, t:tensor):\n",
    "    try: return t.cpu().numpy()\n",
    "    except: return t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def set_meta(self:Tensor, x, copy_meta=False):\n",
    "    \"Set all metadata in `__dict__`\"\n",
    "    if not hasattr(x,'__dict__'): return\n",
    "    d = x.__dict__\n",
    "    if copy_meta:\n",
    "        d = copy(d)\n",
    "        if '_meta' in d: d['_meta'] = copy(d['_meta'])\n",
    "    self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_meta(self:Tensor, n, d=None):\n",
    "    \"Set `n` from `self._meta` if it exists and returns default `d` otherwise\"\n",
    "    return getattr(self, '_meta', {}).get(n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __array_eq__(self:Tensor,b):\n",
    "    return torch.equal(self,b) if self.dim() else self==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def as_subclass(self:Tensor, typ):\n",
    "    \"Cast to `typ` and include `__dict__` and meta\"\n",
    "    return retain_meta(self, torch.as_subclass(self, typ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if not hasattr(torch,'as_subclass'):\n",
    "    setattr(torch, 'as_subclass', torch.Tensor.as_subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorBase(Tensor):\n",
    "    def __new__(cls, x, **kwargs):\n",
    "        res = cast(tensor(x), cls)\n",
    "        if kwargs: res._meta = kwargs\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _before_cast(cls, x): return tensor(x)\n",
    "\n",
    "    def __reduce_ex__(self,proto):\n",
    "        torch.utils.hooks.warn_if_has_hooks(self)\n",
    "        args = (type(self), self.storage(), self.storage_offset(), tuple(self.size()), self.stride())\n",
    "        if self.is_quantized: args = args + (self.q_scale(), self.q_zero_point())\n",
    "        f = _fa_rebuild_qtensor if self.is_quantized else  _fa_rebuild_tensor\n",
    "        return (f, args + (self.requires_grad, OrderedDict()))\n",
    "\n",
    "    def gi(self, i):\n",
    "        res = self[i]\n",
    "        return res.as_subclass(type(self)) if isinstance(res,Tensor) else res\n",
    "\n",
    "    def __repr__(self):\n",
    "        return re.sub('tensor', self.__class__.__name__, super().__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _patch_tb():\n",
    "    if getattr(TensorBase,'_patched',False): return\n",
    "    TensorBase._patched = True\n",
    "\n",
    "    def get_f(fn):\n",
    "        def _f(self, *args, **kwargs):\n",
    "            cls = self.__class__\n",
    "            res = getattr(super(TensorBase, self), fn)(*args, **kwargs)\n",
    "            return retain_type(res, self, copy_meta=True)\n",
    "        return _f\n",
    "\n",
    "    t = tensor([1])\n",
    "    skips = 'as_subclass imag real __getitem__ __class__ __deepcopy__ __delattr__ __dir__ __doc__ __getattribute__ __hash__ __init__ \\\n",
    "        __init_subclass__ __new__ __reduce__ __reduce_ex__ __repr__ __module__ __setstate__'.split()\n",
    "\n",
    "    for fn in dir(t):\n",
    "        if fn in skips: continue\n",
    "        f = getattr(t, fn)\n",
    "        if isinstance(f, (MethodWrapperType, BuiltinFunctionType, BuiltinMethodType, MethodType, FunctionType)):\n",
    "            setattr(TensorBase, fn, get_f(fn))\n",
    "\n",
    "_patch_tb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorImageBase(TensorBase):\n",
    "    _show_args = ArrayImageBase._show_args\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        return show_image(self, ctx=ctx, **{**self._show_args, **kwargs})\n",
    "    \n",
    "class TensorImage(TensorImageBase): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
