{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp transforms.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforms.tabular\n",
    "\n",
    "> Contains all the transforms relevent to deployment in the `fastai` tabular library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure tabular is installed, if not throw error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastinference_pytorch.soft_dependencies import SoftDependencies\n",
    "if not SoftDependencies.check()['tab']:\n",
    "    raise ImportError(\"The tabular module is not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import tensor\n",
    "from fastcore.utils import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Encoder', 'Normalize', 'FillMissing', 'Categorify', 'Categorize'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastinference_pytorch.rebuild import load_data\n",
    "data = load_data('../')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example we'll use the first five rows of the `ADULT_SAMPLE` dataset, which I have converted to a `NumPy` array below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder():\n",
    "    \"\"\"\n",
    "    Single class which handles tabular pre-processing. Will extract\n",
    "    all relevent information from `dictionary` needed for transformations\n",
    "    \n",
    "    Arguments:\n",
    "    `dictionary`: dict, export from `fastinference`\n",
    "    \"\"\"\n",
    "    \n",
    "    can_decode,order = True, 1\n",
    "    def __init__(self, dictionary):\n",
    "        self.fm = dictionary['FillMissing']\n",
    "        self.categorify = dictionary['Categorify']\n",
    "        self.norm = dictionary['Normalize']\n",
    "        self.encoder = dictionary['Encoder']\n",
    "        for var in self.categorify['classes']:\n",
    "            self.categorify['classes'][var][np.nan] = 0\n",
    "        self.tensorize = Tensorize(self.encoder)\n",
    "        \n",
    "    def __call__(self, x, decode=False):\n",
    "        if not decode:\n",
    "            x = self._fill_missing(x)\n",
    "            x = self._categorify(x)\n",
    "            x = self._normalize(x)\n",
    "            x = self.tensorize(x)\n",
    "            return x\n",
    "    \n",
    "    def _fill_missing(self, x):\n",
    "        \"Fills in mising data in `conts` and potentially generates a new categorical column\"\n",
    "        for idx, name in self.encoder['conts'].items():\n",
    "            if name in self.fm['na_dict'].keys():\n",
    "                nan = np.argwhere(x[:,idx]!=x[:,idx])\n",
    "                x[:,idx][nan] = self.fm['na_dict'][name]\n",
    "            if self.fm['add_col']:\n",
    "                x = np.append(x, np.expand_dims(x[:,idx]==x[:,idx],1), 1)\n",
    "        return x\n",
    "    \n",
    "    def _categorify(self, x):\n",
    "        \"Encodes categorical data in `x` based on `self.categorify\"\n",
    "        for idx, name in self.encoder['cats'].items():\n",
    "            x[:,idx] = [self.categorify['classes'][name][i] for i in x[:,idx]]\n",
    "        return x\n",
    "    \n",
    "    def _normalize(self, x):\n",
    "        \"Normalize continous data in `x` based on `self.normalize`\"\n",
    "        for idx, name in self.encoder['conts'].items():\n",
    "            x[:,idx] = (x[:,idx]-self.norm['means'][name])/self.norm['stds'][name]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tensorize():\n",
    "    def __init__(self, enc:Encoder):\n",
    "        \"\"\"\n",
    "        Converts numpy array to a `tensor`.\n",
    "        \n",
    "        Params:\n",
    "        \n",
    "        `enc`: Encoder exported from `fastinference`\n",
    "        \"\"\"\n",
    "        cat_idxs = list(enc['cats'].keys())\n",
    "        cont_idxs = list(enc['conts'].keys())\n",
    "        store_attr(self, 'cat_idxs, cont_idxs')\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        cat = np.take(x, self.cat_idxs, axis=1).astype('int')\n",
    "        cont = np.take(x, self.cont_idxs, axis=1).astype('float')\n",
    "        return tensor(cat), tensor(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(data)\n",
    "t_df = enc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NumpyDataset():\n",
    "    def __init__(self, cats, conts,bs):\n",
    "        \"A simply dataset for NumPy after grouping\"\n",
    "        store_attr(self, 'cats,conts,bs')\n",
    "        self.n_batches = len(cats) // self.bs + (0 if len(cats)%self.bs == 0 else 1)\n",
    "    def __getitem__(self, idx): return (self.cats[idx:idx+self.bs], self.conts[idx:idx+self.bs])\n",
    "    \n",
    "    def __len__(self): return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = NumpyDataset(*t_df, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 5,  8,  3,  0,  6,  5,  2],\n",
       "          [ 5, 13,  1,  5,  2,  5,  2],\n",
       "          [ 5, 12,  1,  0,  5,  3,  2],\n",
       "          [ 6, 15,  3, 11,  1,  2,  2],\n",
       "          [ 7,  6,  3,  9,  6,  3,  2],\n",
       "          [ 5, 12,  5,  7,  4,  5,  2],\n",
       "          [ 5, 16,  1,  0,  3,  5,  2],\n",
       "          [ 5,  2,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  3,  4,  1,  5,  2],\n",
       "          [ 6, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5, 10,  5,  0,  4,  3,  2],\n",
       "          [ 5,  2,  5,  2,  4,  5,  2],\n",
       "          [ 5,  9,  3,  0,  6,  5,  2],\n",
       "          [ 5, 10,  3,  0,  1,  5,  2],\n",
       "          [ 5,  9,  3, 13,  1,  5,  2],\n",
       "          [ 5, 12,  7,  0,  5,  5,  2],\n",
       "          [ 5,  1,  3,  8,  1,  5,  2],\n",
       "          [ 5, 13,  5,  0,  2,  5,  2],\n",
       "          [ 8, 13,  1,  0,  2,  5,  2],\n",
       "          [ 5, 10,  3, 11,  1,  5,  2],\n",
       "          [ 5, 16,  3,  0,  6,  3,  2],\n",
       "          [ 5, 12,  5,  7,  4,  3,  2],\n",
       "          [ 5,  7,  1, 13,  2,  5,  2],\n",
       "          [ 5, 12,  4,  0,  4,  3,  2],\n",
       "          [ 5, 12,  3,  4,  1,  5,  2],\n",
       "          [ 6, 13,  3,  5,  1,  5,  2],\n",
       "          [ 7, 16,  1,  0,  5,  5,  2],\n",
       "          [ 6, 16,  3,  0,  1,  5,  2],\n",
       "          [ 5, 15,  5, 11,  4,  2,  2],\n",
       "          [ 5,  2,  3,  0,  1,  5,  2],\n",
       "          [ 5,  8,  5,  2,  2,  5,  2],\n",
       "          [ 5, 12,  5, 13,  3,  5,  2],\n",
       "          [ 5, 10,  3,  5,  1,  5,  2],\n",
       "          [ 5, 16,  5, 13,  2,  3,  2],\n",
       "          [ 2, 11,  3,  0,  1,  5,  2],\n",
       "          [ 3, 12,  5,  0,  5,  1,  2],\n",
       "          [ 3, 12,  1,  2,  5,  5,  2],\n",
       "          [ 3,  8,  5,  0,  2,  5,  2],\n",
       "          [ 7, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5,  8,  1,  0,  5,  3,  2],\n",
       "          [ 5, 12,  3,  0,  4,  5,  2],\n",
       "          [ 5, 12,  5,  7,  4,  5,  2],\n",
       "          [ 5, 13,  5,  5,  2,  5,  2],\n",
       "          [ 5, 10,  5,  2,  2,  2,  2],\n",
       "          [ 3, 13,  1,  5,  5,  5,  2],\n",
       "          [ 5, 12,  3,  0,  1,  1,  2],\n",
       "          [ 5, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  5, 15,  2,  5,  2],\n",
       "          [ 3, 13,  7, 11,  5,  5,  2],\n",
       "          [ 3, 13,  5,  0,  2,  5,  2],\n",
       "          [ 5, 10,  3,  0,  1,  5,  2],\n",
       "          [ 5, 16,  5,  0,  4,  5,  2],\n",
       "          [ 5, 12,  5, 15,  5,  3,  2],\n",
       "          [ 7,  8,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  5, 13,  4,  5,  2],\n",
       "          [ 7, 16,  3,  0,  6,  5,  2],\n",
       "          [ 5, 10,  3,  2,  1,  5,  2],\n",
       "          [ 7, 16,  1,  0,  2,  5,  2],\n",
       "          [ 2, 10,  3,  0,  1,  2,  2],\n",
       "          [ 7, 10,  3,  0,  1,  5,  2],\n",
       "          [ 1, 10,  3,  1,  1,  5,  2],\n",
       "          [ 7, 11,  3,  0,  1,  5,  2],\n",
       "          [ 5,  1,  3,  9,  4,  5,  2],\n",
       "          [ 5,  1,  3,  4,  1,  5,  2],\n",
       "          [ 5, 16,  3, 13,  1,  5,  2],\n",
       "          [ 6, 16,  3, 13,  1,  5,  2],\n",
       "          [ 5, 16,  1,  9,  2,  5,  2],\n",
       "          [ 5, 16,  3,  0,  3,  5,  2],\n",
       "          [ 3, 12,  5,  2,  4,  5,  2],\n",
       "          [ 5, 13,  7,  0,  2,  5,  2],\n",
       "          [ 5, 12,  3, 15,  6,  5,  2],\n",
       "          [ 5,  9,  3,  8,  1,  5,  2],\n",
       "          [ 5, 16,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  5,  9,  2,  3,  2],\n",
       "          [ 7,  9,  1,  0,  5,  5,  2],\n",
       "          [ 5, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5,  2,  5,  0,  3,  5,  2],\n",
       "          [ 5, 10,  3,  0,  1,  5,  2],\n",
       "          [ 3, 13,  3, 11,  6,  2,  2],\n",
       "          [ 5, 12,  5,  0,  2,  5,  2],\n",
       "          [ 7,  9,  3,  0,  6,  5,  2],\n",
       "          [ 5,  1,  5,  0,  4,  5,  2],\n",
       "          [ 5, 13,  3, 11,  1,  5,  2],\n",
       "          [ 5, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5, 16,  5,  2,  5,  5,  2],\n",
       "          [ 5, 12,  5,  0,  2,  5,  2],\n",
       "          [ 5,  6,  5,  0,  2,  5,  2],\n",
       "          [ 5, 12,  3,  4,  1,  5,  2],\n",
       "          [ 1,  3,  5,  1,  2,  5,  2],\n",
       "          [ 5,  2,  5,  0,  4,  5,  2],\n",
       "          [ 5, 16,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  3,  8,  1,  5,  2],\n",
       "          [ 5, 16,  6,  0,  3,  3,  2],\n",
       "          [ 5, 12,  3,  6,  1,  5,  2],\n",
       "          [ 5, 16,  3,  0,  1,  5,  2],\n",
       "          [ 5, 10,  5,  5,  2,  5,  2],\n",
       "          [ 3, 12,  5,  0,  2,  1,  2],\n",
       "          [ 3,  9,  3,  0,  6,  5,  2],\n",
       "          [ 5,  2,  3,  4,  1,  5,  2],\n",
       "          [ 5, 12,  3,  5,  1,  5,  2],\n",
       "          [ 5, 16,  5,  2,  4,  2,  2],\n",
       "          [ 5, 12,  5,  0,  4,  5,  2],\n",
       "          [ 5, 10,  6,  0,  4,  4,  2],\n",
       "          [ 5, 12,  3,  0,  1,  5,  2],\n",
       "          [ 6, 12,  3,  0,  1,  5,  2],\n",
       "          [ 6, 10,  5, 11,  2,  5,  2],\n",
       "          [ 5, 16,  6,  9,  5,  5,  2],\n",
       "          [ 5,  2,  5,  0,  4,  5,  2],\n",
       "          [ 3, 10,  5,  0,  3,  5,  2],\n",
       "          [ 5,  1,  3,  0,  1,  5,  2],\n",
       "          [ 7, 16,  3,  0,  1,  5,  2],\n",
       "          [ 5, 12,  3,  0,  1,  5,  2],\n",
       "          [ 5, 13,  3, 11,  1,  5,  2],\n",
       "          [ 7,  2,  3,  5,  1,  5,  2],\n",
       "          [ 6, 15,  3, 11,  1,  5,  2],\n",
       "          [ 5,  8,  1,  0,  2,  5,  2],\n",
       "          [ 5,  9,  1,  0,  5,  5,  2],\n",
       "          [ 1, 16,  3,  0,  1,  5,  2],\n",
       "          [ 5, 16,  1,  0,  4,  5,  2],\n",
       "          [ 5,  2,  5,  9,  4,  5,  2],\n",
       "          [ 5, 16,  1, 13,  2,  5,  2],\n",
       "          [ 5,  8,  5,  9,  2,  2,  2],\n",
       "          [ 5, 10,  1,  5,  2,  5,  2],\n",
       "          [ 5, 15,  3, 11,  6,  5,  2],\n",
       "          [ 1, 12,  5,  0,  4,  5,  2],\n",
       "          [ 3, 13,  3, 11,  1,  5,  2],\n",
       "          [ 5, 11,  3,  0,  1,  5,  2]]]),\n",
       " tensor([[[ 7.6238e-01, -8.3426e-01,  7.5269e-01],\n",
       "          [ 3.9657e-01,  4.5299e-01,  1.5365e+00],\n",
       "          [-4.2393e-02, -8.8307e-01, -3.1066e-02],\n",
       "          [-4.2393e-02, -7.2469e-01,  1.9283e+00],\n",
       "          [ 2.5025e-01, -1.0151e+00, -3.1066e-02],\n",
       "          [-1.3593e+00, -1.1965e+00, -4.2295e-01],\n",
       "          [ 7.6238e-01, -1.3750e+00, -3.1066e-02],\n",
       "          [-1.1555e-01, -4.7668e-01, -1.2067e+00],\n",
       "          [ 5.4289e-01,  1.3224e+00, -4.2295e-01],\n",
       "          [-1.8871e-01,  2.6255e-01, -3.1066e-02],\n",
       "          [-1.1398e+00,  3.2330e+00,  1.1446e+00],\n",
       "          [-1.5056e+00,  2.5849e-01, -3.1066e-02],\n",
       "          [-6.2768e-01, -3.5264e-01, -3.1066e-02],\n",
       "          [-6.2768e-01, -1.2718e+00, -3.1066e-02],\n",
       "          [ 3.2341e-01, -9.9261e-01, -3.1066e-02],\n",
       "          [ 9.0870e-01,  9.0527e-01, -4.2295e-01],\n",
       "          [-4.2393e-02, -1.7979e-01, -3.1066e-02],\n",
       "          [-2.6188e-01,  6.8631e-01,  1.5365e+00],\n",
       "          [ 1.2745e+00,  8.0815e-01,  1.5365e+00],\n",
       "          [ 4.6973e-01,  7.4975e-01, -3.1066e-02],\n",
       "          [ 1.0393e-01, -1.3993e-03, -3.1066e-02],\n",
       "          [-9.2032e-01,  5.2976e+00, -4.2295e-01],\n",
       "          [ 5.4289e-01, -6.7947e-01, -3.1066e-02],\n",
       "          [-7.0084e-01,  1.0258e+01, -3.1066e-02],\n",
       "          [ 7.6238e-01,  5.5325e-01, -4.2295e-01],\n",
       "          [ 1.2013e+00,  3.1867e-01,  1.5365e+00],\n",
       "          [ 6.1606e-01,  2.3436e-01, -3.1066e-02],\n",
       "          [ 1.7709e-01, -3.6120e-01, -3.1066e-02],\n",
       "          [-8.4716e-01, -3.4229e-01, -3.1066e-02],\n",
       "          [ 2.5025e-01, -1.1314e+00, -1.2067e+00],\n",
       "          [ 5.4289e-01,  1.5658e+00, -3.1066e-02],\n",
       "          [-1.5056e+00, -9.2736e-01, -4.2295e-01],\n",
       "          [ 4.6973e-01,  5.0664e-01,  1.1446e+00],\n",
       "          [ 1.7709e-01, -4.6099e-01, -3.1066e-02],\n",
       "          [ 6.1606e-01, -8.2047e-01, -3.1066e-02],\n",
       "          [-2.6188e-01, -7.7806e-01, -4.2295e-01],\n",
       "          [ 3.9657e-01, -3.6992e-01, -3.1066e-02],\n",
       "          [-7.0084e-01,  2.1922e+00, -3.1066e-02],\n",
       "          [-1.8871e-01,  4.7835e-01, -3.1066e-02],\n",
       "          [ 3.0768e-02, -3.7036e-01, -3.1066e-02],\n",
       "          [-1.1398e+00,  3.2161e-01, -4.2295e-01],\n",
       "          [-1.4325e+00,  7.0575e-01, -4.2295e-01],\n",
       "          [-7.0084e-01, -3.0252e-01, -3.1066e-02],\n",
       "          [-1.0666e+00, -2.5185e-01,  1.1446e+00],\n",
       "          [ 5.4289e-01, -6.1801e-01, -3.1066e-02],\n",
       "          [-6.2768e-01,  2.6350e-01, -3.1066e-02],\n",
       "          [-3.3504e-01,  7.2921e-01, -3.1066e-02],\n",
       "          [ 1.0550e+00,  4.0710e-01, -3.1066e-02],\n",
       "          [-7.0084e-01, -4.0274e-01, -4.2295e-01],\n",
       "          [ 7.6238e-01, -1.0478e+00,  1.5365e+00],\n",
       "          [-4.8136e-01,  3.9753e-01,  1.5365e+00],\n",
       "          [ 2.5025e-01, -1.4526e+00, -3.1066e-02],\n",
       "          [-1.3593e+00, -1.2620e+00, -3.1066e-02],\n",
       "          [-1.0666e+00, -7.3797e-01, -4.2295e-01],\n",
       "          [-4.2393e-02, -5.3029e-01, -3.1066e-02],\n",
       "          [-1.8871e-01, -3.1372e-01, -3.1066e-02],\n",
       "          [ 2.5025e-01,  1.4812e+00, -3.1066e-02],\n",
       "          [ 1.4208e+00,  2.7747e-01,  1.1446e+00],\n",
       "          [ 5.4289e-01,  5.3832e-01, -3.1066e-02],\n",
       "          [-3.3504e-01,  2.1413e-02, -3.1066e-02],\n",
       "          [ 1.0550e+00,  7.1133e-01,  1.1446e+00],\n",
       "          [ 2.0061e+00, -1.1157e-01, -3.1066e-02],\n",
       "          [-4.8136e-01, -1.1768e+00,  2.3202e+00],\n",
       "          [-9.9348e-01,  1.1984e-02, -1.5986e+00],\n",
       "          [ 6.1606e-01, -2.4024e-01, -3.1066e-02],\n",
       "          [ 1.6403e+00, -5.0893e-02, -3.1066e-02],\n",
       "          [ 1.1282e+00,  1.6990e-01, -3.1066e-02],\n",
       "          [ 2.2988e+00, -8.2200e-01, -3.1066e-02],\n",
       "          [-1.3593e+00, -4.0286e-01, -3.1066e-02],\n",
       "          [-1.1398e+00, -5.6895e-01, -4.2295e-01],\n",
       "          [ 1.6403e+00, -8.4886e-01, -3.1066e-02],\n",
       "          [-5.5452e-01, -6.2441e-01, -4.2295e-01],\n",
       "          [ 2.5025e-01,  1.2670e+00,  3.6081e-01],\n",
       "          [-5.5452e-01,  1.8127e+00, -3.1066e-02],\n",
       "          [-7.7400e-01, -1.4368e+00, -3.1066e-02],\n",
       "          [-4.2393e-02, -1.1727e+00, -3.1066e-02],\n",
       "          [-5.5452e-01,  5.5242e-02, -4.2295e-01],\n",
       "          [-1.4325e+00, -1.9474e-01, -1.2067e+00],\n",
       "          [ 9.0870e-01,  8.9020e-01,  1.1446e+00],\n",
       "          [ 1.7709e-01, -5.5750e-02,  1.5365e+00],\n",
       "          [-1.2861e+00, -1.5140e+00, -4.2295e-01],\n",
       "          [-9.9348e-01, -7.1423e-01, -3.1066e-02],\n",
       "          [-1.5788e+00, -4.3494e-01, -1.5986e+00],\n",
       "          [-4.0820e-01,  1.2261e-01, -3.1066e-02],\n",
       "          [-7.0084e-01,  5.1870e-01, -3.1066e-02],\n",
       "          [-4.0820e-01,  6.3659e-01, -3.1066e-02],\n",
       "          [-8.4716e-01, -3.7131e-01, -3.1066e-02],\n",
       "          [-6.2768e-01,  5.8961e-01, -3.1066e-02],\n",
       "          [-7.7400e-01, -1.2134e+00, -3.1066e-02],\n",
       "          [-1.2130e+00,  6.3570e-01, -8.1483e-01],\n",
       "          [-1.5056e+00, -1.7628e-01, -3.1066e-02],\n",
       "          [ 3.2341e-01, -6.8372e-01, -3.1066e-02],\n",
       "          [ 3.2341e-01,  5.6085e-01, -4.2295e-01],\n",
       "          [-1.8871e-01,  5.5585e-03, -3.1066e-02],\n",
       "          [ 3.0768e-02,  7.6389e-01, -3.1066e-02],\n",
       "          [ 6.8922e-01, -1.4504e+00, -3.1066e-02],\n",
       "          [-4.0820e-01, -1.3194e+00,  1.1446e+00],\n",
       "          [-3.3504e-01, -1.5821e+00, -4.2295e-01],\n",
       "          [ 3.0768e-02, -1.3819e+00, -3.1066e-02],\n",
       "          [-7.7400e-01, -3.3477e-01, -3.1066e-02],\n",
       "          [ 5.4289e-01,  2.0552e+00, -3.1066e-02],\n",
       "          [-1.3593e+00, -5.2979e-01, -3.1066e-02],\n",
       "          [-1.4325e+00, -3.8444e-01, -3.1066e-02],\n",
       "          [ 8.3554e-01, -1.6384e-01, -3.1066e-02],\n",
       "          [-8.4716e-01,  1.3960e-01, -4.2295e-01],\n",
       "          [ 1.6403e+00, -3.8508e-01, -4.2295e-01],\n",
       "          [-3.3504e-01, -1.2042e+00,  1.1446e+00],\n",
       "          [-5.5452e-01,  2.0377e+00, -3.1066e-02],\n",
       "          [-1.5788e+00, -5.3660e-01, -3.1066e-02],\n",
       "          [-1.1398e+00,  6.1819e-01,  1.1446e+00],\n",
       "          [-1.2861e+00, -2.3971e-01, -3.1066e-02],\n",
       "          [ 8.3554e-01, -6.1115e-01, -3.1066e-02],\n",
       "          [-4.8136e-01, -5.5876e-01, -3.1066e-02],\n",
       "          [-1.1555e-01, -6.8160e-01,  1.5365e+00],\n",
       "          [ 7.6238e-01,  5.7502e-01, -1.2067e+00],\n",
       "          [ 1.2745e+00, -8.6184e-01, -3.1066e-02],\n",
       "          [-3.3504e-01,  1.8721e-01,  7.5269e-01],\n",
       "          [ 1.0550e+00, -4.4368e-01, -3.1066e-02],\n",
       "          [ 2.3719e+00,  5.8147e-01, -3.1066e-02],\n",
       "          [-1.8871e-01,  1.0321e-01, -3.1066e-02],\n",
       "          [-6.2768e-01,  2.2520e+00, -3.1066e-02],\n",
       "          [ 5.4289e-01, -1.2292e+00, -3.1066e-02],\n",
       "          [-8.4716e-01, -6.1884e-01,  7.5269e-01],\n",
       "          [-5.5452e-01, -1.9184e-01, -3.1066e-02],\n",
       "          [ 9.8186e-01,  3.8870e-01,  1.9283e+00],\n",
       "          [-6.2768e-01,  1.0407e+00, -4.2295e-01],\n",
       "          [ 8.3554e-01, -4.1750e-01, -3.1066e-02],\n",
       "          [ 6.1606e-01, -7.0937e-01,  2.3202e+00]]], dtype=torch.float64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 8, 3, 0, 6, 5, 2])\n",
      "tensor([ 5, 16,  5,  0,  4,  3,  2])\n",
      "tensor([ 6, 10,  3,  0,  1,  5,  2])\n",
      "tensor([5, 2, 5, 0, 4, 5, 2])\n",
      "tensor([ 5, 12,  3,  0,  6,  5,  2])\n",
      "tensor([ 2, 10,  3,  0,  1,  5,  2])\n",
      "tensor([ 5, 12,  1,  0,  2,  5,  2])\n",
      "tensor([ 5, 13,  5,  0,  2,  2,  2])\n",
      "tensor([ 7, 12,  5,  9,  3,  5,  2])\n",
      "tensor([ 3, 16,  3,  9,  1,  5,  2])\n",
      "tensor([ 5, 12,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 16,  5,  4,  2,  5,  2])\n",
      "tensor([ 5, 16,  3,  4,  1,  5,  2])\n",
      "tensor([5, 3, 5, 7, 4, 3, 2])\n",
      "tensor([ 5, 12,  3, 15,  1,  5,  2])\n",
      "tensor([ 1, 16,  5,  1,  2,  5,  2])\n",
      "tensor([5, 5, 3, 4, 1, 5, 2])\n",
      "tensor([ 7, 12,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 10,  6, 13,  5,  5,  2])\n",
      "tensor([1, 2, 3, 1, 1, 5, 2])\n",
      "tensor([ 5, 13,  3, 11,  1,  5,  2])\n",
      "tensor([ 5, 12,  6,  9,  2,  5,  2])\n",
      "tensor([ 7, 12,  3,  6,  1,  5,  2])\n",
      "tensor([5, 5, 1, 9, 5, 5, 2])\n",
      "tensor([ 5, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 16,  5,  2,  2,  1,  2])\n",
      "tensor([ 3, 12,  7, 11,  2,  5,  2])\n",
      "tensor([ 6, 10,  1, 11,  2,  5,  2])\n",
      "tensor([5, 2, 5, 8, 3, 5, 2])\n",
      "tensor([ 5, 12,  5, 13,  4,  5,  2])\n",
      "tensor([ 5, 12,  1,  9,  5,  5,  2])\n",
      "tensor([ 7,  8,  3, 13,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 16,  1,  9,  2,  5,  2])\n",
      "tensor([ 5, 12,  5,  4,  4,  5,  2])\n",
      "tensor([ 5, 16,  1, 14,  2,  5,  2])\n",
      "tensor([ 3, 12,  3, 12,  1,  5,  2])\n",
      "tensor([ 1, 15,  3,  1,  1,  5,  2])\n",
      "tensor([ 5, 12,  5, 13,  4,  5,  2])\n",
      "tensor([5, 1, 3, 8, 1, 5, 2])\n",
      "tensor([ 5, 16,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 16,  5,  2,  5,  5,  2])\n",
      "tensor([5, 2, 3, 4, 1, 5, 2])\n",
      "tensor([ 5, 12,  5,  2,  2,  5,  2])\n",
      "tensor([ 5, 10,  5,  9,  4,  5,  2])\n",
      "tensor([ 8, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 12,  5,  2,  4,  5,  2])\n",
      "tensor([5, 3, 3, 2, 6, 3, 2])\n",
      "tensor([ 7, 12,  3,  5,  1,  5,  2])\n",
      "tensor([ 7, 12,  3,  6,  1,  2,  2])\n",
      "tensor([ 8, 10,  3, 14,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  7,  1,  5,  2])\n",
      "tensor([ 5, 10,  3,  5,  1,  5,  2])\n",
      "tensor([5, 9, 5, 5, 4, 5, 2])\n",
      "tensor([ 5, 10,  3, 11,  6,  5,  2])\n",
      "tensor([ 5, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 12,  5, 13,  4,  3,  2])\n",
      "tensor([ 3, 13,  1, 11,  2,  1,  2])\n",
      "tensor([ 5,  9,  3, 11,  1,  5,  2])\n",
      "tensor([5, 3, 3, 4, 1, 5, 2])\n",
      "tensor([5, 1, 3, 4, 1, 3, 2])\n",
      "tensor([ 5, 12,  5,  4,  2,  5,  2])\n",
      "tensor([ 2, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 6, 12,  3, 13,  1,  5,  2])\n",
      "tensor([5, 2, 3, 8, 1, 5, 2])\n",
      "tensor([ 5, 12,  6,  2,  5,  5,  2])\n",
      "tensor([ 7, 10,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 10,  5, 11,  2,  5,  2])\n",
      "tensor([5, 3, 1, 7, 2, 5, 2])\n",
      "tensor([ 5, 12,  3,  9,  6,  3,  2])\n",
      "tensor([ 5, 13,  3, 11,  6,  5,  2])\n",
      "tensor([5, 9, 3, 4, 1, 5, 2])\n",
      "tensor([ 5, 12,  1,  4,  5,  5,  2])\n",
      "tensor([ 2, 12,  5,  5,  5,  5,  2])\n",
      "tensor([ 5,  1,  5, 13,  4,  5,  2])\n",
      "tensor([ 3,  6,  3, 15,  1,  5,  2])\n",
      "tensor([1, 1, 5, 1, 4, 5, 2])\n",
      "tensor([5, 8, 1, 4, 2, 5, 2])\n",
      "tensor([ 8, 12,  7,  2,  2,  5,  2])\n",
      "tensor([ 5, 15,  1, 11,  2,  5,  2])\n",
      "tensor([ 5, 10,  1, 11,  2,  5,  2])\n",
      "tensor([ 5, 12,  1,  2,  5,  5,  2])\n",
      "tensor([ 6, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 10,  5,  5,  2,  5,  2])\n",
      "tensor([ 8, 16,  5,  2,  2,  4,  2])\n",
      "tensor([ 7, 12,  3,  2,  6,  5,  2])\n",
      "tensor([ 5,  2,  7, 13,  4,  3,  2])\n",
      "tensor([ 5, 16,  3,  8,  1,  3,  2])\n",
      "tensor([ 3, 16,  5,  2,  4,  5,  2])\n",
      "tensor([ 7, 12,  5,  4,  3,  1,  2])\n",
      "tensor([ 1, 12,  2,  1,  6,  5,  2])\n",
      "tensor([ 7, 12,  1, 15,  2,  5,  2])\n",
      "tensor([ 5, 16,  3, 13,  1,  5,  2])\n",
      "tensor([ 3, 16,  5,  2,  4,  1,  2])\n",
      "tensor([ 5, 16,  5, 13,  4,  1,  2])\n",
      "tensor([ 7, 15,  3, 11,  1,  5,  2])\n",
      "tensor([ 5, 13,  3, 11,  1,  5,  2])\n",
      "tensor([ 5, 16,  5, 13,  4,  5,  2])\n",
      "tensor([ 5, 12,  7, 13,  5,  5,  2])\n",
      "tensor([ 5, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5,  1,  7, 14,  5,  5,  2])\n",
      "tensor([ 2, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5,  8,  5, 11,  2,  5,  2])\n",
      "tensor([ 5, 12,  1,  5,  2,  5,  2])\n",
      "tensor([ 5, 10,  3, 13,  1,  5,  2])\n",
      "tensor([ 5,  7,  5, 13,  5,  5,  2])\n",
      "tensor([ 5, 10,  3,  2,  1,  5,  2])\n",
      "tensor([ 6, 13,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 12,  3, 12,  1,  5,  2])\n",
      "tensor([ 5, 12,  1,  9,  2,  5,  2])\n",
      "tensor([ 7, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 10,  5, 13,  2,  5,  2])\n",
      "tensor([ 5, 12,  3, 15,  1,  5,  2])\n",
      "tensor([ 7, 16,  3,  4,  1,  1,  2])\n",
      "tensor([ 5, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 7, 12,  3,  6,  1,  5,  2])\n",
      "tensor([ 5, 10,  5, 11,  2,  5,  2])\n",
      "tensor([ 5, 12,  6, 14,  4,  5,  2])\n",
      "tensor([ 8, 16,  3,  5,  6,  5,  2])\n",
      "tensor([ 3, 10,  5, 11,  4,  5,  2])\n",
      "tensor([ 5, 12,  1,  9,  2,  5,  2])\n",
      "tensor([ 8, 13,  3, 11,  6,  5,  2])\n",
      "tensor([ 7, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  9,  6,  5,  2])\n",
      "tensor([5, 5, 3, 8, 1, 2, 2])\n",
      "tensor([ 3, 12,  1,  5,  5,  1,  2])\n",
      "tensor([ 5, 13,  3,  5,  1,  5,  2])\n",
      "tensor([ 7, 12,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 10,  5, 11,  2,  5,  2])\n",
      "tensor([1, 5, 3, 1, 1, 5, 2])\n",
      "tensor([ 2, 10,  5, 11,  2,  5,  2])\n",
      "tensor([7, 9, 3, 4, 1, 5, 2])\n",
      "tensor([ 5, 12,  1, 13,  2,  5,  2])\n",
      "tensor([ 5, 12,  5,  2,  4,  5,  2])\n",
      "tensor([ 5, 16,  3, 11,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  2,  6,  3,  2])\n",
      "tensor([ 5, 12,  3, 13,  1,  5,  2])\n",
      "tensor([ 5, 11,  5,  2,  4,  5,  2])\n",
      "tensor([ 5, 12,  1,  4,  4,  5,  2])\n",
      "tensor([ 2,  8,  1, 11,  5,  2,  2])\n",
      "tensor([1, 2, 5, 1, 4, 5, 2])\n",
      "tensor([ 2, 16,  5,  5,  4,  5,  2])\n",
      "tensor([ 5, 13,  1, 11,  2,  5,  2])\n",
      "tensor([5, 2, 5, 9, 4, 3, 2])\n",
      "tensor([5, 7, 5, 4, 3, 3, 2])\n",
      "tensor([ 2, 10,  5,  5,  4,  5,  2])\n",
      "tensor([ 5, 15,  3, 11,  1,  5,  2])\n",
      "tensor([5, 2, 5, 6, 4, 5, 2])\n",
      "tensor([ 5, 12,  3, 15,  1,  5,  2])\n",
      "tensor([ 5, 12,  1, 13,  2,  5,  2])\n",
      "tensor([ 5, 16,  5, 14,  3,  5,  2])\n",
      "tensor([ 5, 10,  3, 13,  1,  5,  2])\n",
      "tensor([ 5, 12,  3,  4,  1,  3,  2])\n",
      "tensor([ 3, 13,  3, 11,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  8,  1,  5,  2])\n",
      "tensor([7, 9, 1, 9, 5, 5, 2])\n",
      "tensor([ 5, 12,  5,  2,  4,  5,  2])\n",
      "tensor([ 5, 12,  5,  5,  2,  5,  2])\n",
      "tensor([ 5,  9,  1, 11,  2,  5,  2])\n",
      "tensor([ 5, 12,  1, 15,  2,  5,  2])\n",
      "tensor([1, 1, 5, 1, 4, 5, 2])\n",
      "tensor([3, 8, 3, 6, 1, 5, 2])\n",
      "tensor([ 5, 12,  1, 13,  5,  5,  2])\n",
      "tensor([ 5, 12,  3, 13,  6,  5,  2])\n",
      "tensor([ 8,  9,  7, 11,  5,  5,  2])\n",
      "tensor([ 5, 12,  5,  9,  5,  5,  2])\n",
      "tensor([ 5, 12,  6,  9,  5,  5,  2])\n",
      "tensor([ 5, 16,  5,  2,  5,  3,  2])\n",
      "tensor([ 5, 12,  3,  2,  6,  5,  2])\n",
      "tensor([ 3, 12,  5,  8,  4,  5,  2])\n",
      "tensor([ 8, 16,  3, 12,  1,  5,  2])\n",
      "tensor([5, 1, 1, 8, 5, 5, 2])\n",
      "tensor([ 7, 10,  5, 12,  2,  5,  2])\n",
      "tensor([ 5, 16,  3, 13,  1,  5,  2])\n",
      "tensor([5, 6, 3, 7, 1, 5, 2])\n",
      "tensor([ 8, 16,  5,  2,  4,  5,  2])\n",
      "tensor([5, 1, 3, 5, 6, 5, 2])\n",
      "tensor([ 5, 12,  1, 12,  2,  5,  2])\n",
      "tensor([ 3, 13,  5, 11,  2,  5,  2])\n",
      "tensor([ 5, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 12,  6,  9,  5,  3,  2])\n",
      "tensor([ 5, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 13,  1, 11,  2,  5,  2])\n",
      "tensor([ 2, 16,  3,  2,  1,  5,  2])\n",
      "tensor([5, 4, 3, 4, 1, 3, 2])\n",
      "tensor([ 3, 12,  6,  9,  2,  3,  2])\n",
      "tensor([ 5, 12,  6,  5,  5,  5,  2])\n",
      "tensor([ 3, 16,  5,  4,  2,  5,  2])\n",
      "tensor([ 3, 16,  5,  2,  5,  5,  2])\n",
      "tensor([ 5, 10,  5,  4,  2,  5,  2])\n",
      "tensor([ 5, 12,  5,  8,  5,  3,  2])\n",
      "tensor([ 5, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 16,  5,  9,  4,  5,  2])\n",
      "tensor([ 7, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 7, 16,  3,  6,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  8,  1,  5,  2])\n",
      "tensor([ 5, 13,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 13,  4, 12,  2,  2,  2])\n",
      "tensor([ 5, 12,  4, 14,  2,  5,  2])\n",
      "tensor([ 8, 16,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 12,  6,  4,  2,  5,  2])\n",
      "tensor([ 5, 16,  5,  9,  2,  2,  2])\n",
      "tensor([ 5, 10,  5, 11,  2,  5,  2])\n",
      "tensor([ 5,  9,  6, 14,  5,  3,  2])\n",
      "tensor([ 5, 12,  5,  9,  4,  5,  2])\n",
      "tensor([ 2, 12,  3,  2,  1,  5,  2])\n",
      "tensor([ 5, 10,  3, 11,  1,  5,  2])\n",
      "tensor([3, 7, 1, 9, 2, 5, 2])\n",
      "tensor([ 5, 12,  7, 13,  5,  5,  2])\n",
      "tensor([ 7, 12,  3, 11,  1,  5,  2])\n",
      "tensor([ 5, 16,  3, 13,  1,  5,  2])\n",
      "tensor([ 1, 12,  5,  1,  2,  5,  2])\n",
      "tensor([ 5, 12,  3,  7,  1,  3,  2])\n",
      "tensor([ 5, 12,  5, 13,  5,  3,  2])\n",
      "tensor([ 5, 10,  5,  2,  4,  5,  2])\n",
      "tensor([ 3,  2,  3, 15,  1,  5,  2])\n",
      "tensor([ 5, 16,  3, 14,  1,  2,  2])\n",
      "tensor([ 5, 10,  5, 13,  2,  5,  2])\n",
      "tensor([ 7, 15,  3, 11,  1,  5,  2])\n",
      "tensor([ 1, 16,  5,  1,  4,  5,  2])\n",
      "tensor([ 5, 12,  5,  8,  2,  5,  2])\n",
      "tensor([ 6, 13,  5, 11,  2,  5,  2])\n",
      "tensor([ 7, 12,  3,  6,  1,  2,  2])\n",
      "tensor([ 5, 15,  3, 11,  1,  5,  2])\n",
      "tensor([ 2, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 12,  6,  5,  4,  5,  2])\n",
      "tensor([ 6, 12,  5,  5,  2,  5,  2])\n",
      "tensor([ 5, 10,  5,  4,  2,  5,  2])\n",
      "tensor([ 5, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 5, 12,  1, 15,  2,  5,  2])\n",
      "tensor([ 5, 12,  6,  4,  4,  5,  2])\n",
      "tensor([ 7, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 16,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 16,  5,  9,  4,  5,  2])\n",
      "tensor([ 5, 12,  3, 14,  1,  5,  2])\n",
      "tensor([5, 7, 3, 6, 6, 5, 2])\n",
      "tensor([ 5, 12,  3,  2,  1,  5,  2])\n",
      "tensor([ 5, 10,  5,  5,  2,  5,  2])\n",
      "tensor([ 5, 10,  5,  5,  5,  5,  2])\n",
      "tensor([ 5, 10,  6, 13,  2,  5,  2])\n",
      "tensor([ 5, 12,  5,  4,  2,  4,  2])\n",
      "tensor([ 5, 12,  6,  8,  5,  5,  2])\n",
      "tensor([ 5,  8,  3, 14,  1,  5,  2])\n",
      "tensor([ 5, 12,  5,  6,  4,  5,  2])\n",
      "tensor([ 5, 12,  7,  5,  2,  5,  2])\n",
      "tensor([ 7, 12,  3,  4,  1,  5,  2])\n",
      "tensor([ 5, 12,  3,  9,  6,  5,  2])\n",
      "tensor([ 5, 10,  3,  5,  1,  5,  2])\n",
      "tensor([ 1, 16,  5,  1,  4,  5,  2])\n",
      "tensor([ 5, 12,  6,  7,  2,  3,  2])\n",
      "tensor([ 5, 13,  3,  5,  1,  5,  2])\n",
      "tensor([ 8, 13,  5, 11,  2,  5,  2])\n",
      "tensor([ 5, 10,  3, 11,  6,  5,  2])\n",
      "tensor([5, 2, 5, 7, 2, 3, 2])\n",
      "tensor([ 5, 16,  1, 13,  5,  5,  2])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-f773dc0c0dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "for batch in dset:\n",
    "    print(batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tensorize(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5,  8,  3,  0,  6,  5,  2],\n",
       "         [ 5, 13,  1,  5,  2,  5,  2],\n",
       "         [ 5, 12,  1,  0,  5,  3,  2],\n",
       "         [ 6, 15,  3, 11,  1,  2,  2],\n",
       "         [ 7,  6,  3,  9,  6,  3,  2],\n",
       "         [ 5, 12,  5,  7,  4,  5,  2],\n",
       "         [ 5, 16,  1,  0,  3,  5,  2],\n",
       "         [ 5,  2,  3,  0,  1,  5,  2],\n",
       "         [ 5, 12,  3,  4,  1,  5,  2],\n",
       "         [ 6, 12,  3,  0,  1,  5,  2],\n",
       "         [ 5, 10,  5,  0,  4,  3,  2],\n",
       "         [ 5,  2,  5,  2,  4,  5,  2]]),\n",
       " tensor([[ 0.7624, -0.8343,  0.7527],\n",
       "         [ 0.3966,  0.4530,  1.5365],\n",
       "         [-0.0424, -0.8831, -0.0311],\n",
       "         [-0.0424, -0.7247,  1.9283],\n",
       "         [ 0.2503, -1.0151, -0.0311],\n",
       "         [-1.3593, -1.1965, -0.4229],\n",
       "         [ 0.7624, -1.3750, -0.0311],\n",
       "         [-0.1156, -0.4767, -1.2067],\n",
       "         [ 0.5429,  1.3224, -0.4229],\n",
       "         [-0.1887,  0.2625, -0.0311],\n",
       "         [-1.1398,  3.2330,  1.1446],\n",
       "         [-1.5056,  0.2585, -0.0311]], dtype=torch.float64))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 µs, sys: 0 ns, total: 30 µs\n",
      "Wall time: 31.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = np.take(arr, list(enc.encoder['cats'].keys())).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 3, 5, 6, 7, 8, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encoder['cats'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ms ± 5.07 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = np.append(arr, np.expand_dims(arr[:,4]==arr[:,4],1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.92 ms ± 4.47 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "b = np.zeros((arr.shape[0], arr.shape[1]+1), dtype=np.object)\n",
    "b[:len(arr), :-1] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FillMissing(arr, procs):\n",
    "    \"Fills in missing data in `conts` and potentially generates a new categorical column\"\n",
    "    for idx, name in procs['Inputs']['conts'].items():\n",
    "        if name in procs['FillMissing']['na_dict'].keys():\n",
    "            nan = np.argwhere(arr[:,idx]!=arr[:,idx])\n",
    "            arr[:,idx][nan] = procs['FillMissing']['na_dict'][name]\n",
    "        if procs['FillMissing']['add_col']:\n",
    "            arr = np.append(arr, np.expand_dims(arr[:,4]==arr[:,4],1), 1)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FillMissing\" class=\"doc_header\"><code>FillMissing</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FillMissing</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Fills in missing data in `conts` and potentially generates a new categorical column"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FillMissing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arr` is expected to be a `NumPy` array, while `procs` should be the pre-processing dictionary exported after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = FillMissing(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k', True, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three `bool` columns were added at the end for our potential missing numerical values (if `True` they exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Categorize(arr, procs):\n",
    "    \"Encodes categorical data in `arr` based on `procs`\"\n",
    "    for idx, name in procs['Inputs']['cats'].items():\n",
    "        arr[:,idx] = [procs['Categorize'][name][i] for i in arr[:,idx]]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Categorize\" class=\"doc_header\"><code>Categorize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Categorize</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Encodes categorical data in `arr` based on `procs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Categorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arr` is expected to be a `NumPy` array, while `procs` should be the pre-processing dictionary exported after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k', True, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = Categorize(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0, 1902, 40,\n",
       "       ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our categorical variables are now all converted to integers. Any left as strings are not used by the model and are ignored at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Normalize(arr, procs):\n",
    "    \"Normalizes continous data in `arr` based on `procs`\"\n",
    "    for idx, name in procs['Inputs']['conts'].items():\n",
    "        arr[:,idx] = (arr[:,idx]-procs['Normalize'][name]['mean'])/procs['Normalize'][name]['std']\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Normalize\" class=\"doc_header\"><code>Normalize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Normalize</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Normalizes continous data in `arr` based on `procs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arr` is expected to be a `NumPy` array, while `procs` should be the pre-processing dictionary exported after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0, 1902, 40,\n",
       "       ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = Normalize(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7634343827572744, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0,\n",
       "       1902, 40, ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our continous variables have now been adjusted for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_procs(arr, procs):\n",
    "    \"Apply test-time pre-processing on `NumPy` array input\"\n",
    "    arr = FillMissing(arr, procs)\n",
    "    arr = Categorize(arr, procs)\n",
    "    arr = Normalize(arr, procs)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"apply_procs\" class=\"doc_header\"><code>apply_procs</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>apply_procs</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Apply test-time pre-processing on `NumPy` array input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(apply_procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific order in which the pre-processing is done must occur, as `Categorify` can increase by a few columns from `FillMissing` if multiple `is_na` columns are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "df = df.head().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = apply_procs(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7634343827572744, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0,\n",
       "       1902, 40, ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularDataset():\n",
    "    \"A tabular `PyTorch` dataset based on `procs` with batch size `bs` on `device`\"\n",
    "    def __init__(self, arr, procs, bs=64, device='cuda'):\n",
    "        \"Stores array, grabs the indicies for `cats` and `conts`, and generates batches\"\n",
    "        self.arr = arr\n",
    "        self.cat_idxs = procs['Inputs']['cats'].keys()\n",
    "        self.cont_idxs = procs['Inputs']['conts'].keys()\n",
    "        self.bs = bs\n",
    "        self.device = device\n",
    "        self.make_batches()\n",
    "        \n",
    "    def __getitem__(self, x):\n",
    "        \"Grabs one batch of data and converts it to the proper type\"\n",
    "        row = [self.batches[x][:, list(self.cat_idxs)], self.batches[x][:, list(self.cont_idxs)]]\n",
    "        row[0] = tensor(row[0].astype(np.int64)).to(self.device)\n",
    "        row[1] = tensor(row[1].astype(np.float32)).to(self.device)\n",
    "        return row\n",
    "        \n",
    "    def make_batches(self):\n",
    "        \"Splits data into equal sized batches, excluding the final partial\"\n",
    "        n_splits = len(self.arr)//self.bs\n",
    "        last = len(self.arr) - (len(self.arr) - (n_splits * self.bs))\n",
    "        if len(self.arr) > self.bs:\n",
    "            arrs = np.split(self.arr[:last], n_splits)\n",
    "            arrs.append(self.arr[last:])\n",
    "        else:\n",
    "            arrs = [self.arr]\n",
    "        self.batches = arrs\n",
    "        \n",
    "    def __len__(self): return len(self.arr)//self.bs + (0 if len(self.arr)%self.bs==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TabularDataset\" class=\"doc_header\"><code>class</code> <code>TabularDataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TabularDataset</code>(**`arr`**, **`procs`**, **`bs`**=*`64`*, **`device`**=*`'cuda'`*)\n",
       "\n",
       "A tabular `PyTorch` dataset based on `procs` with batch size `bs` on `device`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TabularDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TabularDataset.__init__\" class=\"doc_header\"><code>TabularDataset.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TabularDataset.__init__</code>(**`arr`**, **`procs`**, **`bs`**=*`64`*, **`device`**=*`'cuda'`*)\n",
       "\n",
       "Stores array, grabs the indicies for `cats` and `conts`, and generates batches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TabularDataset.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TabularDataset.make_batches\" class=\"doc_header\"><code>TabularDataset.make_batches</code><a href=\"__main__.py#L20\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TabularDataset.make_batches</code>()\n",
       "\n",
       "Splits data into equal sized batches, excluding the final partial"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TabularDataset.make_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "df = df.head().to_numpy()\n",
    "df = apply_procs(df, procs)\n",
    "dset = TabularDataset(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 5,  8,  3,  0,  6,  5,  2],\n",
       "         [ 5, 13,  1,  5,  2,  5,  2],\n",
       "         [ 5, 12,  1,  0,  5,  3,  1],\n",
       "         [ 6, 15,  3, 11,  1,  2,  2],\n",
       "         [ 7,  6,  3,  9,  6,  3,  1]], device='cuda:0'),\n",
       " tensor([[ 7.6343e-01,  1.0132e+05,  1.2000e+01],\n",
       "         [ 3.9687e-01,  2.3675e+05,  1.4000e+01],\n",
       "         [-4.3010e-02,  9.6185e+04,  1.0000e+01],\n",
       "         [-4.3010e-02,  1.1285e+05,  1.5000e+01],\n",
       "         [ 2.5024e-01,  8.2297e+04,  1.0000e+01]], device='cuda:0')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class tabular_learner():\n",
    "    \"A `Learner`-like wrapper for tabular data\"\n",
    "    def __init__(self, data_fn, model_fn):\n",
    "        \"Accepts a `data_fn` and a `model_fn` corresponding to the named picle exports\"\n",
    "        map_location = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
    "        self.model = torch.load(model_fn, map_location=map_location)\n",
    "        self.model.eval()\n",
    "        with open(data_fn, 'rb') as handle:\n",
    "            self.procs = pickle.load(handle)\n",
    "            for proc in self.procs['Categorize']:\n",
    "                self.procs['Categorize'][proc][np.nan] = 0 # we can't pickle np.nan\n",
    "            \n",
    "    def test_dl(self, test_items, bs=64):\n",
    "        \"Applies `procs` to `test_items`\"\n",
    "        dl = apply_procs(test_items, self.procs)\n",
    "        return TabularDataset(dl, self.procs, bs=bs)\n",
    "    \n",
    "    def predict(self, inps):\n",
    "        \"Predict a single tensor\"\n",
    "        with torch.no_grad():\n",
    "            outs = self.model(*inps)\n",
    "        outs = np.argmax(outs.cpu().numpy(), axis=1)\n",
    "        outs = [learn.procs['Outputs'][i] for i in outs]\n",
    "        return outs\n",
    "    \n",
    "    def get_preds(self, dl=None):\n",
    "        \"Predict on multiple batches of data in `dl`\"\n",
    "        outs = []\n",
    "        for i, batch in enumerate(dl):\n",
    "            outs += self.predict(batch)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"tabular_learner\" class=\"doc_header\"><code>class</code> <code>tabular_learner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>tabular_learner</code>(**`data_fn`**, **`model_fn`**)\n",
       "\n",
       "A `Learner`-like wrapper for tabular data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.__init__\" class=\"doc_header\"><code>tabular_learner.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.__init__</code>(**`data_fn`**, **`model_fn`**)\n",
       "\n",
       "Accepts a `data_fn` and a `model_fn` corresponding to the named picle exports"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "learn = tabular_learner('procs.pkl', 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.test_dl\" class=\"doc_header\"><code>tabular_learner.test_dl</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.test_dl</code>(**`test_items`**, **`bs`**=*`64`*)\n",
       "\n",
       "Applies `procs` to `test_items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "dl = learn.test_dl(df.iloc[:5].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 5,  8,  3,  0,  6,  5,  2],\n",
       "         [ 5, 13,  1,  5,  2,  5,  2],\n",
       "         [ 5, 12,  1,  0,  5,  3,  1],\n",
       "         [ 6, 15,  3, 11,  1,  2,  2],\n",
       "         [ 7,  6,  3,  9,  6,  3,  1]], device='cuda:0'),\n",
       " tensor([[ 7.6343e-01,  1.0132e+05,  1.2000e+01],\n",
       "         [ 3.9687e-01,  2.3675e+05,  1.4000e+01],\n",
       "         [-4.3010e-02,  9.6185e+04,  1.0000e+01],\n",
       "         [-4.3010e-02,  1.1285e+05,  1.5000e+01],\n",
       "         [ 2.5024e-01,  8.2297e+04,  1.0000e+01]], device='cuda:0')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "dl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.predict\" class=\"doc_header\"><code>tabular_learner.predict</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.predict</code>(**`inps`**)\n",
       "\n",
       "Predict a single tensor"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<50k', '<50k', '<50k', '<50k', '<50k']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "learn.predict(dl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.get_preds\" class=\"doc_header\"><code>tabular_learner.get_preds</code><a href=\"__main__.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.get_preds</code>(**`dl`**=*`None`*)\n",
       "\n",
       "Predict on multiple batches of data in `dl`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.get_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<50k', '<50k', '<50k', '<50k', '<50k']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "learn.get_preds(dl=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
